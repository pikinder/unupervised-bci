{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning from Label Proportions Brain-Computer Interface\n",
    "The current script contains a basic implementation of LLP for BCI using the data from our original publication [HÃ¼bner et al. (2017)](https://arxiv.org/pdf/1701.07213.pdf). You can also take a look at the condensed version from the 2016 NIPS Workshop on _Reliable Machine-Learning in the wild_ [here](https://0586f9b3-a-62cb3a1a-s-sites.googlegroups.com/site/wildml2016nips/KindermansPaper.pdf?attachauth=ANoY7cpKZPUUwVoVdBmJmXGGGbkOtk2rFCN-D0dIPY7MxTG0Fn5DE473nJT-f7pb4TpHVSnkbkiRBurfF82BLE1qwIL4u69Gchko0Bjp5m8fPPorhxQwnDqLrDI3GX9xezDiC30JYprsFiW9yEGcFCeEXxNf3AUvll-bzGSojnp47sZbtCOK51bygl-dMd3RqsSpumd36h4cNKuGMfRXkvt3khtwDwp1F4iLEHXysYvlxOVC8dEGfGA%3D&attredirects=0).\n",
    "\n",
    "The script performs the following.\n",
    "* Select a subject\n",
    "* Set the required variables to fit the experiment\n",
    "* Load the data (which can be obtained [here](https://zenodo.org/record/192684#.WO6PuBhh3EZ))\n",
    "* Extract the required variables from the mat files\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from tools.preprocess import flatten_normalise_bias\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the subject\n",
    "options are: 'S1',....,'S13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject = 'S5'\n",
    "data_folder = 'storage/raw_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration settings\n",
    "Do not modify these\n",
    "* **n_trials**: the number of trials/symbols spelled\n",
    "* **ratio**: the ratio of target to non-target in the different sequence types. This makes it weakly supervised but does not provide explicit label information.\n",
    "* **pos_neg_ratio**: the global target to non-target ratio. This has makes it weakly supervised. But it is not explicit label information.\n",
    "* **n_short**: the number of stimuli highlighted in the short sequence. This allows us to assign the stimuli to the short or the long sequence.\n",
    "* **bad_stimuli**: the stimuli that correspond to the non-selectable symbols.\n",
    "* **good_stimuli**: the selectable stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_trials = 63*3\n",
    "ratio = np.array([2./18.,3./8.,]) # long, short\n",
    "\n",
    "# the ratio below will be used to estimate X.T y\n",
    "pos_neg_ratio = np.array([[16./68., -52./68]])\n",
    "n_short = 12 # Number of stimuli highlighted in a short sequence.\n",
    "bad_stimuli = [2,4,7,13,17,22,27,32,35,37]\n",
    "good_stimuli = [i for i in range(42) if i not in bad_stimuli]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and extract the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mf = loadmat('%s/%s'%(data_folder,subject))\n",
    "channels = [c[0] for c in mf['epo']['clab'][0][0][0]]\n",
    "\n",
    "# Extract the labels, this is the only form of explicit label information\n",
    "# It is not used to train the classifier.\n",
    "labels = mf['epo']['y'][0][0][0].reshape(n_trials,-1)\n",
    "\n",
    "# Extract the stimuli\n",
    "# this involves retaining only the good stimuli and re-labelling the other ones\n",
    "stimuli = mf['epo']['stimuli'][0][0].T[:,good_stimuli]\n",
    "stimuli = np.dot(stimuli,np.diag(np.r_[:stimuli.shape[1]]+1))-1\n",
    "stimuli = stimuli.reshape((n_trials,-1,stimuli.shape[1]))\n",
    "\n",
    "# Extract the groups\n",
    "group = np.sum(stimuli>=0,axis=2)==n_short\n",
    "\n",
    "# Extract the eeg\n",
    "eeg = mf['epo']['x'][0][0]\n",
    "eeg = eeg.transpose(2,1,0)\n",
    "eeg = eeg.reshape(n_trials,-1,eeg.shape[1],eeg.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the components, collect data X and groups G.\n",
    "The groups G and data X will be used to train the classifier.\n",
    "Knowing the groups G enables us to estimate the class means without labelled data. These mean estimate will in turn allow us to train a least squares classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.vstack([flatten_normalise_bias(e) for e in eeg])\n",
    "G = group.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier\n",
    "Normally, a least squares classifier has the following solution:\n",
    "$$ w = (X^T X + \\lambda I)^{-1} X^T y.$$\n",
    "\n",
    "The first component \n",
    "$$ (X^T X + \\lambda I)^{-1} $$\n",
    "does not depend on label information and is estimated directly.\n",
    "The second component\n",
    "$$ X^T y$$\n",
    "can be re-written as\n",
    "$$ \\sum_{i=1}^N x_i^T y_i. $$\n",
    "With $y_i\\in\\{-1,1\\}$ this can be re-written as:\n",
    "$$N*( p_+ \\mu_+  - (1-p_+) \\mu_-).$$\n",
    "Here $N$ is the number of stimuli presented to the user and $p_+$ is the percentage of target responses in X and it is a known parameter of the BCI paragigm.\n",
    "Therefore we only have to estimate $\\mu_+,\\mu_-$ to estimate the weight vector $w$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using LLP to estimate the means $\\mu_+,\\mu_-$\n",
    "Now we use the key idea behind LLP to estimate $\\mu_+,\\mu_-$.\n",
    "\n",
    "If we know which stimuli $x_i$ belong to the long sequence $l$ with a $\\frac{2}{18}$ target to non-target ratio and which stimuli belong to the short sequence $s$ with a $\\frac{3}{8}$ target to target ratio we can compute the sequence means $$\\mu_l,~~~\\mu_s^T.$$\n",
    "\n",
    "Now using the ratios $\\Pi$:\n",
    "$$\\Pi=\\left[\\begin{array}{cc}\n",
    "\\frac{2}{18} & \\frac{3}{8}\\\\\n",
    "\\frac{16}{18} & \\frac{5}{8}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "we can estimate the class means.\n",
    "These means are:\n",
    "$$\n",
    "\\left[\\begin{array}{c}\n",
    "\\mu_+\\\\\n",
    "\\mu_-\n",
    "\\end{array}\\right]\n",
    "=\n",
    "(\\Pi^T)^{-1}\n",
    "\\left[\\begin{array}{c}\n",
    "\\mu_l\\\\\n",
    "\\mu_s\n",
    "\\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the groupwise mean\n",
    "MU_G = np.array([X[G==g].mean(axis=0) for g in range(2)])\n",
    "\n",
    "# Estimate the classwise mean from the groupwise mean\n",
    "P = np.vstack([ratio,1.-ratio])\n",
    "MU_C = np.dot(np.linalg.inv(P.T),MU_G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing $X^T y = N*( p_+ \\mu_+  - (1-p_+) \\mu_-).$\n",
    "Using the estimated means we do not require labels for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XTy = X.shape[0]*np.dot(pos_neg_ratio,MU_C).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing $ (X^T X + \\lambda I)^{-1} $\n",
    "This does not require labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regularisation constant. From ERP experience a value of 10^3 is not absurdly high\n",
    "lmbd = 1000.\n",
    "# Compute the regularised design matrix: (X^T X + \\lambda I)^{-1}\n",
    "XTX = np.dot(X.T,X)+lmbd*np.eye(X.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute $ w=(X^T X + \\lambda I)^{-1} X^T y$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = np.dot(np.linalg.inv(XTX),XTy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the classifier (AUC)\n",
    "and realise that this classifier is trained without labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867230148232\n"
     ]
    }
   ],
   "source": [
    "print roc_auc_score(labels.flatten(),np.dot(X,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
